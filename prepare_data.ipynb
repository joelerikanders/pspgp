{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"alymc7kzsUSY"},"outputs":[],"source":["import pandas as pd\n","import time\n","import os\n","from datetime import datetime\n","from collections import defaultdict\n","\n","!pip install polars==0.18.2\n","import polars as pl"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J7OETwfNvB8h"},"outputs":[],"source":["%cd drive/My\\ Drive/performance_prediction"]},{"cell_type":"code","source":["# convert kaggle data to parquet\n","pd.read_csv(\"data/train.csv\").to_parquet(\"data/train.parquet\")"],"metadata":{"id":"dTPSq1UfK_Vd","executionInfo":{"status":"ok","timestamp":1689703715926,"user_tz":-120,"elapsed":504,"user":{"displayName":"Joel Erikanders","userId":"04337617043785976076"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# parse raw data\n","\n","files1 = [\n","    'data/JOWILDER_20200401_to_20200430/JOWILDER_20200401_to_20200430_7fbb180_events',\n","    \"data/JOWILDER_20200801_to_20200831/JOWILDER_20200801_to_20200831_7fbb180_events\",\n","    \"data/JOWILDER_20200901_to_20200930/JOWILDER_20200901_to_20200930_7fbb180_events\",\n","]\n","\n","files2 = [\n","    'data/JOWILDER_20211101_to_20211130/JOWILDER_20211101_to_20211130_42454c6_events',\n","    'data/JOWILDER_20220701_to_20220731/JOWILDER_20220701_to_20220731_e3039cf_events',\n","    'data/JOWILDER_20220801_to_20220831/JOWILDER_20220801_to_20220831_e3039cf_events',\n","    'data/JOWILDER_20220601_to_20220630/JOWILDER_20220601_to_20220630_e3039cf_events',\n","    'data/JOWILDER_20210701_to_20210731/JOWILDER_20210701_to_20210731_42454c6_events',\n","    'data/JOWILDER_20210801_to_20210831/JOWILDER_20210801_to_20210831_42454c6_events',\n","    'data/JOWILDER_20210901_to_20210930/JOWILDER_20210901_to_20210930_42454c6_events',\n","    'data/JOWILDER_20211201_to_20211231/JOWILDER_20211201_to_20211231_42454c6_events',\n","    'data/JOWILDER_20211001_to_20211031/JOWILDER_20211001_to_20211031_42454c6_events',\n","    'data/JOWILDER_20210601_to_20210630/JOWILDER_20210601_to_20210630_42454c6_events',\n","    'data/JOWILDER_20210101_to_20210131/JOWILDER_20210101_to_20210131_42454c6_events',\n","    'data/JOWILDER_20210201_to_20210228/JOWILDER_20210201_to_20210228_42454c6_events',\n","    \"data/JOWILDER_20221001_to_20221031/JOWILDER_20221001_to_20221031_40e77cd_events\",\n","    \"data/JOWILDER_20221101_to_20221130/JOWILDER_20221101_to_20221130_40e77cd_events\",\n","    \"data/JOWILDER_20191101_to_20191130/JOWILDER_20191101_to_20191130_10bbaaf_events\",\n","    \"data/JOWILDER_20220301_to_20220331/JOWILDER_20220301_to_20220331_b751607_events\",\n","    \"data/JOWILDER_20191201_to_20191231/JOWILDER_20191201_to_20191231_10bbaaf_events\",\n","    \"data/JOWILDER_20200101_to_20200131/JOWILDER_20200101_to_20200131_10bbaaf_events\",\n","    \"data/JOWILDER_20220501_to_20220531/JOWILDER_20220501_to_20220531_93eaf7d_events\",\n","    \"data/JOWILDER_20200201_to_20200229/JOWILDER_20200201_to_20200229_10bbaaf_events\",\n","    \"data/JOWILDER_20200301_to_20200331/JOWILDER_20200301_to_20200331_10bbaaf_events\",\n","    \"data/JOWILDER_20200501_to_20200531/JOWILDER_20200501_to_20200531_10bbaaf_events\",\n","    \"data/JOWILDER_20200601_to_20200630/JOWILDER_20200601_to_20200630_10bbaaf_events\",\n","    \"data/JOWILDER_20200701_to_20200731/JOWILDER_20200701_to_20200731_10bbaaf_events\",\n","    \"data/JOWILDER_20220101_to_20220131/JOWILDER_20220101_to_20220131_1df5a3a_events\",\n","    \"data/JOWILDER_20220201_to_20220228/JOWILDER_20220201_to_20220228_dbfe71d_events\",\n","    \"data/JOWILDER_20220401_to_20220430/JOWILDER_20220401_to_20220430_93eaf7d_events\",\n","    \"data/JOWILDER_20220901_to_20220930/JOWILDER_20220901_to_20220930_6228b2e_events\",\n","]\n","\n","def convert_to_timestamp(date_string, formats):\n","    \"\"\"\n","    Converts a date string in some of the formats in the \"formats\" list to milliseconds\n","    \"\"\"\n","    for date_format in formats:\n","        try:\n","            return datetime.strptime(date_string, date_format).timestamp() * 1000\n","        except ValueError:\n","            pass\n","    raise ValueError(f\"No valid format found for {date_string}\")\n","\n","formats = [\"%Y-%m-%d %H:%M:%S.%f\", \"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%dT%H:%M:%S.%f\", \"%Y-%m-%dT%H:%M:%S\"]\n","\n","\n","for file in (files1 + files2):\n","    print(file)\n","\n","    cs = [\"session_id\", \"timestamp\", \"event_data\", \"index\"]\n","\n","    # the raw data in files1 has no index,\n","    # and the time is split in two parts, client_time and client_time_ms\n","    if file in files1:\n","        try:\n","            data = pl.read_csv(file + \".tsv\", separator=\"\\t\")\n","        except:\n","            data = pl.read_csv(file + \".tsv\", separator=\"\\t\", dtypes={\"session_n\": str})\n","        data = data.with_columns(pl.arange(0, pl.col(\"app_id_fast\").count()).over([\"session_id\"]).alias(\"index\"))\n","        data = data.with_columns((pl.col(\"client_time\") + \".\" + pl.col(\"client_time_ms\").cast(pl.Utf8)).alias(\"timestamp\")).rename({\"event_data_complex\": \"event_data\"})\n","        data = data.select(cs)\n","    else:\n","        data = pl.read_csv(file + \".tsv\", separator=\"\\t\").select(cs)\n","\n","    # create the level column,\n","    # for doing some initial filtering of sessions, to speed up the parsing\n","    data = data.with_columns(pl.col(\"event_data\").str.extract('[\"\\']level[\"\\']: (\\d+)', 1).cast(pl.Int32).alias(\"level\"))\n","    data = data.fill_null(-1)\n","    data = data.filter(((pl.col(\"level\").max() > 12) & ((pl.col(\"level\") == 0) & (pl.col(\"index\") > 1)).any() & (pl.col(\"level\") < 23)).over(\"session_id\"))\n","\n","\n","    cols = pl.read_parquet(\"data/train.parquet\", n_rows=1).columns\n","    data = data.rows(named=True)\n","    out_data = {c: [] for c in cols}\n","    labels = {}\n","    fails = []\n","\n","    # iterate over the rows in the raw data and parse each row\n","    for i, r in enumerate(data):\n","\n","        e = r[\"event_data\"]\n","        e = e.replace(\"true\", \"1\")\n","        e = e.replace(\"false\", \"0\")\n","        e = e.replace(\"null\", \"None\")\n","        e = eval(e)\n","\n","        typ = e[\"type\"]\n","        subtyp = e[\"subtype\"]\n","\n","        # skip all rows like these, that are not present in the kaggle data\n","        if typ in [\"quiz\", \"endgame\", \"quizquestion\"]:\n","            continue\n","\n","        if typ == \"startgame\":\n","            hq = e[\"hq\"]\n","            music = e[\"music\"]\n","            fullscreen = e[\"fullscreen\"]\n","            continue\n","\n","\n","        # parse labels\n","        sid = r[\"session_id\"]\n","        if sid not in labels:\n","            labels[sid] = [1] * 18\n","        if \"cur_cmd_fqid\" in e:\n","            ans = e[\"cur_cmd_fqid\"]\n","            if ans in [\n","                \"tunic.capitol_0.hall.boss.chap1_finale_slipfirst_0_fail\",\n","                \"tunic.capitol_0.hall.boss.chap1_finale_plaquefirst_0_fail\"\n","            ]:\n","                labels[sid][2] = 0\n","            for q in range(3):\n","                chap, hall = 1, 0\n","                if ans == f\"tunic.capitol_{hall}.hall.boss.chap{chap}_finale_{q}_fail\":\n","                    labels[sid][q] = 0\n","            for q in range(6):\n","                chap, hall = 2, 1\n","                if ans == f\"tunic.capitol_{hall}.hall.boss.chap{chap}_finale_{q}_fail\":\n","                    labels[sid][q + 3] = 0\n","            if ans == f\"tunic.capitol_1.hall.gramps.chap2_teddy_finale_0_fail\":\n","                labels[sid][9] = 0\n","            if ans == f\"tunic.capitol_1.hall.boss.chap2_teddy_finale_1_fail\":\n","                labels[sid][10] = 0\n","            if ans == f\"tunic.capitol_1.hall.gramps.chap2_teddy_finale_2_fail\":\n","                labels[sid][11] = 0\n","            if ans == f\"tunic.capitol_1.hall.wells.chap2_teddy_finale_3_fail\":\n","                labels[sid][12] = 0\n","            for q in range(5):\n","                chap, hall = 4, 2\n","                if ans == f\"tunic.capitol_{hall}.hall.boss.chap{chap}_finale_{q}_fail\":\n","                    labels[sid][q + 13] = 0\n","\n","\n","        fqid = e[\"fqid\"]\n","        if \"finale\" in str(fqid) and subtyp in [\"wildcard\", \"notebook\"]:\n","            continue\n","        if fqid == \"credits\":\n","            continue\n","        if e[\"room_fqid\"] in [\"tunic.capitol_0.hall\", \"tunic.capitol_1.hall\", \"tunic.capitol_2.hall\"] and subtyp == \"notebook\":\n","            continue\n","\n","        t = r[\"timestamp\"]\n","        et = convert_to_timestamp(t, formats)\n","\n","        # Skipping rows after the checkpoint event most of the time.\n","        # In the kaggle data though there are rows after the checkpoint event,\n","        # if the elapsed_time is decreasing (reversed). Keeping those here to\n","        if len(out_data[\"event_name\"]) > 0 and \"checkpoint\" in out_data[\"event_name\"] and \\\n","         e[\"level\"] in [4, 12, 22] and out_data[\"session_id\"][cpt_ix] == sid and \\\n","         out_data[\"level\"][cpt_ix] == e[\"level\"] and out_data[\"elapsed_time\"][cpt_ix] < et:\n","                continue\n","\n","        if len(out_data[\"session_id\"]) > 0 and out_data[\"session_id\"][-1] != sid and sid in out_data[\"session_id\"]:\n","            continue\n","\n","        if typ == \"click\":\n","            event_name = subtyp + \"_\" + typ\n","        else:\n","            event_name = typ\n","\n","        if typ == \"checkpoint\":\n","            cpt_ix = len(out_data[\"event_name\"])\n","\n","\n","        if typ == \"hover\":\n","            event_name = subtyp + \"_\" + typ\n","            # just for simplicity, dropping the hover rows before training anyway\n","            out_data[\"hover_duration\"].append(1)\n","        else:\n","            out_data[\"hover_duration\"].append(None)\n","\n","        level = e[\"level\"]\n","        if level < 5:\n","            lg = \"0-4\"\n","        elif 5 <= level <= 12:\n","            lg = \"5-12\"\n","        else:\n","            lg = \"13-22\"\n","\n","        # append the parsed data\n","        out_data[\"level_group\"].append(lg)\n","        out_data[\"index\"].append(r[\"index\"])\n","        out_data[\"event_name\"].append(event_name)\n","        out_data[\"session_id\"].append(sid)\n","        out_data[\"name\"].append(e[\"name\"])\n","        out_data[\"text\"].append(None if \"text\" not in e else e[\"text\"])\n","        out_data[\"page\"].append(None if \"page\" not in e else e[\"page\"])\n","        out_data[\"text_fqid\"].append(None if \"text_fqid\" not in e else e[\"text_fqid\"])\n","        out_data[\"fqid\"].append(fqid if fqid else None)\n","        out_data[\"level\"].append(level)\n","        out_data[\"room_fqid\"].append(e[\"room_fqid\"])\n","        out_data[\"room_coor_x\"].append(None if \"room_coor\" not in e else e[\"room_coor\"][0])\n","        out_data[\"room_coor_y\"].append(None if \"room_coor\" not in e else e[\"room_coor\"][1])\n","        out_data[\"screen_coor_x\"].append(None if \"screen_coor\" not in e else e[\"screen_coor\"][0])\n","        out_data[\"screen_coor_y\"].append(None if \"screen_coor\" not in e else e[\"screen_coor\"][1])\n","        out_data[\"hq\"].append(hq)\n","        out_data[\"music\"].append(music)\n","        out_data[\"fullscreen\"].append(fullscreen)\n","        out_data[\"elapsed_time\"].append(et)\n","\n","\n","\n","    d = {k: v for k, v in out_data.items() if len(v) > 0}\n","    df = pl.DataFrame(d)\n","\n","    df = df.with_columns(pl.col(\"elapsed_time\") - pl.col(\"elapsed_time\").min().over(\"session_id\"))\n","    df = df.filter(~(pl.col(\"hover_duration\").is_null() & pl.col(\"room_coor_x\").is_null() & (pl.col(\"event_name\") != \"checkpoint\")))\n","\n","    labels = {k: v for k, v in labels.items() if k in df[\"session_id\"].unique()}\n","    sids = {\"session_id\": [k for k in labels.keys()]}\n","    qs = {f\"q{i}\": [v[i] for v in labels.values()] for i in range(18)}\n","    labels = pl.DataFrame(sids | qs)\n","\n","    df.write_parquet(file + \"_train.parquet\")\n","    labels.write_parquet(file + \"_labels.parquet\")"],"metadata":{"id":"EyoL0R9s_DkN"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jSATdxHzC5Dg"},"outputs":[],"source":["# concatenate the parsed data from the files\n","\n","cs_cols = [\n","    pl.col(\"screen_coor_x\").cast(pl.Float64),\n","    pl.col(\"screen_coor_y\").cast(pl.Float64),\n","]\n","ds = [pl.read_parquet(f + \"_train.parquet\").with_columns(cs_cols) for f in files1 + files2]\n","df = pl.concat(ds)\n","print(df.shape)\n","df.write_parquet(\"data/raw_train.parquet\")\n","\n","ds = [pl.read_parquet(f + \"_labels.parquet\") for f in files1 + files2]\n","df = pl.concat(ds)\n","print(df.shape)\n","df.write_parquet(\"data/raw_labels.parquet\")"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1ceyb_gB704hNpVGSDVmhphHsDfHAGJnR","timestamp":1681450784549}],"gpuType":"T4","mount_file_id":"1ReVyl7UlIEzcoScd8VrgKrpp28RWYHfl","authorship_tag":"ABX9TyOl8eJ1iPulMZbqyIfBB+pf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}